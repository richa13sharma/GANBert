{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwC5OqeZDCJI"
      },
      "source": [
        "# In-scope Prediction \n",
        "\n",
        "Using the CLINC150 dataset in a semi-supervised method, by masking a portion of the labeled data as unlabeled to analyse how well the GAN-BERT does in-scope prediction given unlabeled data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ckgPl4yQ_4WD"
      },
      "source": [
        "Each of the notebooks in this experiment contain the code, statistics, loss & accuracy curves for different variations of splitting the labeled & unlabeled examples that the GAN-BERT model is training on.\n",
        "\n",
        "The first section, namely, 'Base Model/10_90 split' has all the code that is run on the dataset in the proportion of 10-90, containing 10% labeled examples and 90% unlabeled examples.\n",
        "In the subsequent notebooks, the same process is repeated for different variations:\n",
        "- 20_80\n",
        "- 40_60\n",
        "- 60_40\n",
        "- 80_20\n",
        "- 90_10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0RZOLSUUMxt"
      },
      "source": [
        "# Base Model/ 10_90 split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rItvsdM7Tgk1"
      },
      "source": [
        "## Importing necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOAcH6FiUDuA",
        "outputId": "830a6495-9fe0-4c74-b17c-aa87aed981e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.3.2\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (1.21.6)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (4.64.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.3.2) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.3.2) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.2) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.3.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.3.2) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=3a7e7d938f196a224af9d06d5ce79b2ace64af8cf73a1ea181c8228c2e8a9232\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[K     |████████████████████████████████| 452 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 82.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.3.2\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yzDP5FZslqii"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import io\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import *\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj6Wy23MpCLl"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JdliPXikUQu3"
      },
      "outputs": [],
      "source": [
        "# Set random values\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjQpweKxUU5N",
        "outputId": "e92e3a4a-dfd6-4075-e5cd-f9859db97292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MjAspE2Ywj1X"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53cSfHTmpE2T"
      },
      "source": [
        "## Data Processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKhc3WFZDcUW"
      },
      "source": [
        "'data_full.json' is the file from the CLINC150 repository that contains the full variant of the dataset.\n",
        "It consists of 15,000 training examples, with 3,000 validation samples and 4,500 test samples.\n",
        "\n",
        "We decided to use this variant since the small or imbalanced data would not give us accurate results and since we were performing in-scope prediction in this case, the OOS+ variant would not be suitable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwQnd0W-D8IO"
      },
      "source": [
        "Structure:\n",
        "\n",
        "The json file has keys which represent each set. Each set is a list of lists where each list represents one example containing a [sentence, intent].\n",
        "\n",
        "For example, ['what expression would i use to say i love you if i were an italian', 'translate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jjv1V6p_lB_-"
      },
      "outputs": [],
      "source": [
        "with open('data_full.json') as json_file:\n",
        "  data = json.load(json_file)\n",
        "  json_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt0alestlLv_",
        "outputId": "e3b08348-978b-4d28-d46e-a7e10822857f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "['what expression would i use to say i love you if i were an italian', 'translate']\n"
          ]
        }
      ],
      "source": [
        "print(data.keys())\n",
        "print(type(data['train']))\n",
        "print(type(data['train'][0]))\n",
        "print(data['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WSUak9ctLFF",
        "outputId": "f854b41e-63ba-4929-cad6-66ac7fd200c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "151\n",
            "['UNK_UNK', 'translate', 'transfer']\n"
          ]
        }
      ],
      "source": [
        "intent_set = ['UNK_UNK'] # set of all intents\n",
        "for sent in data['train']:\n",
        "  if sent[1] not in intent_set:\n",
        "    intent_set.append(sent[1])\n",
        "\n",
        "print(len(intent_set))\n",
        "print(intent_set[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xteBvTnhEOi6"
      },
      "source": [
        "We have added a label for the unlabeled intent since the data does not inherently contain any unlabeled samples. Hence the total number of classes is 151."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iBGR2WbUtn9x"
      },
      "outputs": [],
      "source": [
        "intent_map = {}\n",
        "for (i, label) in enumerate(intent_set):\n",
        "  intent_map[label] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lT1zkVrDnrpc"
      },
      "outputs": [],
      "source": [
        "def split_labeled(intent_df, labeled_prop,unlabeled_prop):\n",
        "  test_size = unlabeled_prop/ (labeled_prop + unlabeled_prop)\n",
        "  df_labeled, df_unlabeled = train_test_split(intent_df, stratify = intent_df['intent'], test_size = test_size, random_state = 42)\n",
        "\n",
        "  df_labeled = df_labeled.reset_index(drop=True)\n",
        "  df_unlabeled = df_unlabeled.reset_index(drop=True)\n",
        "  print(df_labeled.head())\n",
        "  print(df_unlabeled.head())\n",
        "  print(df_labeled.shape)\n",
        "  print(df_unlabeled.shape)\n",
        "\n",
        "  #add into 2 lists - labeled_examples & unlabeled_examples\n",
        "  labeled_examples = []\n",
        "  unlabeled_examples = []\n",
        "  for i in range(len(df_labeled)):\n",
        "    labeled_examples.append((df_labeled.loc[i, 'text'], df_labeled.loc[i, 'intent']))\n",
        "  \n",
        "  print(labeled_examples[:3])\n",
        "\n",
        "  for i in range(len(df_unlabeled)):\n",
        "    unlabeled_examples.append((df_unlabeled.loc[i, 'text'], 'UNK_UNK'))\n",
        "\n",
        "  print(unlabeled_examples[:3])\n",
        "\n",
        "  return labeled_examples, unlabeled_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BKVdTNlIo4S2",
        "outputId": "3060f79c-5127-402b-f8d1-8cf26dca4b01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-11469792-8ac2-406d-8bc9-a43dfd21a790\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11469792-8ac2-406d-8bc9-a43dfd21a790')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11469792-8ac2-406d-8bc9-a43dfd21a790 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11469792-8ac2-406d-8bc9-a43dfd21a790');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text     intent\n",
              "0  what expression would i use to say i love you ...  translate\n",
              "1  can you tell me how to say 'i do not speak muc...  translate\n",
              "2  what is the equivalent of, 'life is good' in f...  translate\n",
              "3  tell me how to say, 'it is a beautiful morning...  translate\n",
              "4  if i were mongolian, how would i say that i am...  translate"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intent_train_df = pd.DataFrame(data['train'], columns = ['text', 'intent'])\n",
        "intent_train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgvmYbkJEYVG"
      },
      "source": [
        "In this first variation, the split is labeled = 10, unlabeled = 90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvAp6vVin1h7",
        "outputId": "dd1a0d5f-a7df-4773-f5c3-5290f3dc0876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text              intent\n",
            "0                           how is the tire pressure       tire_pressure\n",
            "1  are there any international transaction fees a...  international_fees\n",
            "2      does my car have enough gas to get to detroit                 gas\n",
            "3  i want to find a roundtrip flight from philade...         book_flight\n",
            "4               tell me my car's tire pressure level       tire_pressure\n",
            "                                    text         intent\n",
            "0        disconnect from my phone for me    sync_device\n",
            "1         tell me a few facts about cats       fun_fact\n",
            "2  tell me your guess of what my name is      user_name\n",
            "3     what did i put on my shopping list  shopping_list\n",
            "4        when am i due for a tire change    tire_change\n",
            "(1500, 2)\n",
            "(13500, 2)\n",
            "[('how is the tire pressure', 'tire_pressure'), ('are there any international transaction fees associated with my visa card', 'international_fees'), ('does my car have enough gas to get to detroit', 'gas')]\n",
            "[('disconnect from my phone for me', 'UNK_UNK'), ('tell me a few facts about cats', 'UNK_UNK'), ('tell me your guess of what my name is', 'UNK_UNK')]\n"
          ]
        }
      ],
      "source": [
        "#1st Variation\n",
        "labeled_examples, unlabeled_examples = split_labeled(intent_train_df, labeled_prop=10,unlabeled_prop=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c5BsjpLfCfJ5"
      },
      "outputs": [],
      "source": [
        "# validation \n",
        "val_examples = []\n",
        "for sent in data['val']:\n",
        "  val_examples.append((sent[0], sent[1]))\n",
        "\n",
        "# test\n",
        "test_examples = []\n",
        "for sent in data['test']:\n",
        "  test_examples.append((sent[0], sent[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4R1vrbQ0v-j"
      },
      "source": [
        "Tokenization / Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "80cd277fe3d84768b29f46b90111883d",
            "499fd0748e2349f592d43357b8ea3d69",
            "7237144b1d9d4a039759fb245b9f7ead",
            "eeb80e2d8f3b40ed88bc6fb8c566c006",
            "0e9b70e291f9440293329b3799caff9b",
            "b02c2fe0893b4f26b83969a581184179",
            "c529f5432daf4a7291de8c0ab5b299cc",
            "267b8d6cd50f4f7892aa2c5e15d7bdf2",
            "7cb1124b29e340e6a464e9ded3750b43",
            "62c58e3c470941dd9825c7cb738f982f",
            "20a170be3e8c4219b758daa77d2eece9"
          ]
        },
        "id": "pqxgPFoHzpFA",
        "outputId": "2a8f229e-5381-4636-e331-362e9a304c6a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80cd277fe3d84768b29f46b90111883d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3iMspP52z3-",
        "outputId": "e5b32514-f561-46ab-bb79-875571fb67eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SEP] 102\n",
            "[CLS] 101\n",
            "[PAD] 0\n",
            "[UNK] 100\n"
          ]
        }
      ],
      "source": [
        "# Some of the common BERT tokens\n",
        "print(tokenizer.sep_token, tokenizer.sep_token_id) # marker for ending of a sentence\n",
        "print(tokenizer.cls_token, tokenizer.cls_token_id) # start of each sentence, so BERT knows we’re doing classification\n",
        "print(tokenizer.pad_token, tokenizer.pad_token_id) # special token for padding\n",
        "print(tokenizer.unk_token, tokenizer.unk_token_id) # tokens not found in training set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1JveGKJpxRrX"
      },
      "outputs": [],
      "source": [
        "# tokenizer + dataloader \n",
        "\n",
        "def dataloader(ip_examples, label_masks, intent_map, do_shuffle, balance):\n",
        "  # applying balance\n",
        "  examples = []\n",
        "\n",
        "  # Count the percentage of labeled examples  \n",
        "  num_labeled_examples = 0 \n",
        "  for label_mask in label_masks:\n",
        "    if label_mask: \n",
        "      num_labeled_examples += 1\n",
        "  label_mask_rate = num_labeled_examples/len(ip_examples)\n",
        "\n",
        "  # if required it applies the balance\n",
        "  for index, ex in enumerate(ip_examples): \n",
        "    if label_mask_rate == 1 or not balance: #if all labeled or balancing is not needed\n",
        "      examples.append((ex, label_masks[index]))\n",
        "    else:\n",
        "      # IT SIMULATE A LABELED EXAMPLE\n",
        "      if label_masks[index]:\n",
        "        balance = int(1/label_mask_rate)\n",
        "        balance = int(math.log(balance,2))\n",
        "        if balance < 1:\n",
        "          balance = 1\n",
        "        for b in range(0, int(balance)):\n",
        "          examples.append((ex, label_masks[index]))\n",
        "      else:\n",
        "        examples.append((ex, label_masks[index]))\n",
        "\n",
        "\n",
        "  input_ids = []\n",
        "  input_mask_array = []\n",
        "  label_mask_array = []\n",
        "  label_id_array = []\n",
        "\n",
        "  # tokenization\n",
        "  for (text, label_mask) in examples:\n",
        "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=40, padding=\"max_length\", truncation=True)\n",
        "    input_ids.append(encoded_sent)\n",
        "    label_id_array.append(intent_map[text[1]])\n",
        "    label_mask_array.append(label_mask)\n",
        "\n",
        "  # Attention to token (to ignore padded input wordpieces)\n",
        "  for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
        "    input_mask_array.append(att_mask)\n",
        "\n",
        "  # Convertion to Tensor\n",
        "  input_ids = torch.tensor(input_ids) \n",
        "  input_mask_array = torch.tensor(input_mask_array)\n",
        "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
        "  label_mask_array = torch.tensor(label_mask_array)\n",
        "\n",
        "  # Building the TensorDataset\n",
        "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
        "\n",
        "  if do_shuffle:\n",
        "    sampler = RandomSampler\n",
        "  else:\n",
        "    sampler = SequentialSampler\n",
        "\n",
        "  # Building the DataLoader\n",
        "  return DataLoader(dataset, sampler = sampler(dataset), batch_size = 64) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlNzGGBuIp3A"
      },
      "source": [
        "The sentence with the max length = 33, hence for each sentence in a batch, padding is done to make them all of length 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2LiAUqWs8_-",
        "outputId": "708c1607-0dfa-4d21-beb6-14be28f82b8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-7b370dd84a6f>:56: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  label_mask_array = torch.tensor(label_mask_array)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# label masks - True for labeled, False for unlabeled\n",
        "lab_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
        "unlab_label_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
        "train_label_masks = np.concatenate([lab_label_masks,unlab_label_masks])\n",
        "\n",
        "# train examples - labeled + unlabeled\n",
        "train_examples = labeled_examples + unlabeled_examples\n",
        "\n",
        "# train dataloader \n",
        "train_dataloader = dataloader(train_examples, train_label_masks, intent_map, do_shuffle = True, balance = True)\n",
        "\n",
        "#val dataloader\n",
        "val_label_masks = np.ones(len(val_examples), dtype=bool)\n",
        "val_dataloader = dataloader(val_examples, val_label_masks, intent_map, do_shuffle = False, balance = False)\n",
        "\n",
        "#test dataloader\n",
        "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
        "test_dataloader = dataloader(test_examples, test_label_masks, intent_map, do_shuffle = False, balance = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0r3sGdQdzMy"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7ef90efc0e624776b46d9b4f59661e0a",
            "69d0f8fd67ed47ffa7382bda25cfb96c",
            "69e33f014cb9451e81afc7261cc38fa9",
            "6514207f29be45b1ac913d0925511d92",
            "f48266fae8734a09bd9bc673e89299d7",
            "4e9d3961e0bc42949b7f63e1d9decf0d",
            "856cbeaec00f49ae84f24a00390587ac",
            "85bc12fe0c9e4adf84a4275a9eb10715",
            "e3ee711ea62545ccbad4a99b33e738ea",
            "75019ed62dd9446ebae6700dc9f92a9c",
            "8f721a42d6d640a38c97901b40211b3a",
            "9c537e79551044d08879682ceb1ddb13",
            "99f7c14cb1c644158d7d0fdbf2d4a34c",
            "ef7c05fcde6f4862b77f41cac6c13bc0",
            "c39e68ce32354d55a8674b33863467b9",
            "5506243f1afb4aa2b4aecfd5cf078d6e",
            "18da525d58064fcfb22a6236bd5088b7",
            "46c90c1f75c040ee91f9eac4a7641d7d",
            "67d2461721e64d218ca0bf34ab47e9e5",
            "e4f356fd1db94250a2df23933948d5a7",
            "25f1a996732d48569e14b762201409f0",
            "4a859afe248a468fbdc45a40b0125b91"
          ]
        },
        "id": "P0hcfDZPOYkn",
        "outputId": "1a027c1b-64e4-4c11-92d4-a8cf2a821fc9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ef90efc0e624776b46d9b4f59661e0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c537e79551044d08879682ceb1ddb13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# BERT\n",
        "transformer =  BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oD_-wMT0d_vz"
      },
      "outputs": [],
      "source": [
        "#Generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size, output_size, hidden_sizes, dropout_rate):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [noise_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output_rep = self.layers(noise)\n",
        "        return output_rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xeIbz8kIeGXz"
      },
      "outputs": [],
      "source": [
        "# Discriminator\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_labels, dropout_rate):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
        "        layers = []\n",
        "        hidden_sizes = [input_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        self.layers = nn.Sequential(*layers) #per il flatten\n",
        "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input_rep):\n",
        "        input_rep = self.input_dropout(input_rep)\n",
        "        last_rep = self.layers(input_rep)\n",
        "        logits = self.logit(last_rep)\n",
        "        probs = self.softmax(logits)\n",
        "        return last_rep, logits, probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "apkWunKpF5ql"
      },
      "outputs": [],
      "source": [
        "noise_size = 100\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
        "hidden_size = config.hidden_size # BERT outputs a 768 embedding vector\n",
        "num_hidden_layers_gen = 1\n",
        "hidden_levels_gen = [hidden_size for i in range(0, num_hidden_layers_gen)]\n",
        "num_hidden_layers_disc = 1\n",
        "hidden_levels_disc = [hidden_size for i in range(0, num_hidden_layers_disc)]\n",
        "\n",
        "# dropout to be applied to discriminator's input vectors\n",
        "out_dropout_rate = 0.2\n",
        "\n",
        "num_labels = len(intent_map)\n",
        "\n",
        "generator = Generator(noise_size=noise_size, #100\n",
        "                      output_size=hidden_size, #768\n",
        "                      hidden_sizes=hidden_levels_gen, #[768] \n",
        "                      dropout_rate=out_dropout_rate) #0.2\n",
        "\n",
        "discriminator = Discriminator(input_size=hidden_size, #768\n",
        "                              hidden_sizes=hidden_levels_disc, #[768]\n",
        "                              num_labels=num_labels, #151 - no oos\n",
        "                              dropout_rate=out_dropout_rate) #0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTkVAX72N4jO",
        "outputId": "cf2d6097-0a0c-46dd-893b-826cd68a8ece"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=768, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input dim - 100x768\n",
        "# output dim - 768x768\n",
        "generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsBxCphHN8V4",
        "outputId": "c6d0445e-f766-4d97-f6e7-e7dae213d04e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (input_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (logit): Linear(in_features=768, out_features=152, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input dim - 768x768\n",
        "# output dim - 768x152\n",
        "discriminator  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juw-fYOCOzSb",
        "outputId": "c32d3ec2-f1ea-4642-e2a6-035f84e37fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# input dim - 30522x768\n",
        "# output dim - 768x768\n",
        "transformer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bqaGXwp7UCvj"
      },
      "outputs": [],
      "source": [
        "multi_gpu = True\n",
        "if torch.cuda.is_available():    \n",
        "  generator.cuda()\n",
        "  discriminator.cuda()\n",
        "  transformer.cuda()\n",
        "  if multi_gpu:\n",
        "    transformer = torch.nn.DataParallel(transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oC7NdupTUSq3"
      },
      "outputs": [],
      "source": [
        "#models parameters\n",
        "transformer_vars = [i for i in transformer.parameters()]\n",
        "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
        "g_vars = [v for v in generator.parameters()]\n",
        "\n",
        "learning_rate_generator = 5e-5\n",
        "learning_rate_discriminator = 5e-5\n",
        "\n",
        "#optimizer\n",
        "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
        "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "v96GTfibVs7M"
      },
      "outputs": [],
      "source": [
        "#scheduler\n",
        "apply_scheduler = False\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "if apply_scheduler:\n",
        "  num_train_examples = len(train_examples)\n",
        "  num_train_steps = int(num_train_examples / batch_size * num_epochs)\n",
        "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)\n",
        "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn4H3BUqkLlk"
      },
      "source": [
        "## Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwzIwRaCWOiK",
        "outputId": "fe4f64a6-7c23-441b-c651-392e36714aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:14.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:38.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:03.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:28.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:53.\n",
            "\n",
            "  Average training loss generator: 0.675\n",
            "  Average training loss discriminator: 5.558\n",
            "  Training epoch took: 0:02:54\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.390\n",
            "Saving... 0\n",
            "  Val Loss: 3.457\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.760\n",
            "  Average training loss discriminator: 3.306\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.698\n",
            "Saving... 1\n",
            "  Val Loss: 1.933\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.754\n",
            "  Average training loss discriminator: 1.954\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.839\n",
            "Saving... 2\n",
            "  Val Loss: 1.076\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.740\n",
            "  Average training loss discriminator: 1.254\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.860\n",
            "Saving... 3\n",
            "  Val Loss: 0.750\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.735\n",
            "  Average training loss discriminator: 0.938\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.881\n",
            "Saving... 4\n",
            "  Val Loss: 0.610\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.732\n",
            "  Average training loss discriminator: 0.823\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.890\n",
            "Saving... 5\n",
            "  Val Loss: 0.567\n",
            "  Val took: 0:00:07\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.731\n",
            "  Average training loss discriminator: 0.778\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.892\n",
            "  Val Loss: 0.575\n",
            "  Val took: 0:00:06\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.730\n",
            "  Average training loss discriminator: 0.754\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.893\n",
            "  Val Loss: 0.580\n",
            "  Val took: 0:00:06\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.731\n",
            "  Average training loss discriminator: 0.739\n",
            "  Training epoch took: 0:02:56\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.886\n",
            "  Val Loss: 0.597\n",
            "  Val took: 0:00:06\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    282.    Elapsed: 0:00:25.\n",
            "  Batch    80  of    282.    Elapsed: 0:00:50.\n",
            "  Batch   120  of    282.    Elapsed: 0:01:15.\n",
            "  Batch   160  of    282.    Elapsed: 0:01:40.\n",
            "  Batch   200  of    282.    Elapsed: 0:02:05.\n",
            "  Batch   240  of    282.    Elapsed: 0:02:30.\n",
            "  Batch   280  of    282.    Elapsed: 0:02:55.\n",
            "\n",
            "  Average training loss generator: 0.729\n",
            "  Average training loss discriminator: 0.731\n",
            "  Training epoch took: 0:02:55\n",
            "\n",
            "Running validation...\n",
            "  Accuracy: 0.889\n",
            "  Val Loss: 0.601\n",
            "  Val took: 0:00:06\n"
          ]
        }
      ],
      "source": [
        "# training & validation\n",
        "best_valid_loss = float('inf')\n",
        "model = '10_90'\n",
        "training_stats = []\n",
        "train_gen_loss_history = []\n",
        "train_disc_loss_history = []\n",
        "val_loss_history = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch + 1, num_epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  # loss for each epoch\n",
        "  tr_g_loss = 0\n",
        "  tr_d_loss = 0\n",
        "\n",
        "  transformer.train()\n",
        "  generator.train()\n",
        "  discriminator.train()\n",
        "\n",
        "  for idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update every print_each_n_step batches.\n",
        "    if idx % 40 == 0 and not idx == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        # Report progress.\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(idx, len(train_dataloader), elapsed))\n",
        "\n",
        "    b_input_ids = batch[0].to(device) #tensor of input ids of that batch\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    b_label_mask = batch[3].to(device)\n",
        "\n",
        "    real_batch_size = b_input_ids.shape[0] \n",
        "    # print('real_batch_size: ', real_batch_size) #size of each batch = 64\n",
        "\n",
        "    model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "    hidden_states = model_outputs[-1]\n",
        "    # print('hidden states', hidden_states.size()) #64x768 - 768 per sentence in batch\n",
        "\n",
        "    noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
        "    # print('noise', noise.size()) # 64x100 - 100 per sentence in batch \n",
        "    gen_rep = generator(noise)\n",
        "    # print('gen output', gen_rep.size()) #64x768 \n",
        "    # both transformer + gen output are 768 size\n",
        "\n",
        "    disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
        "    # print('disc input', disciminator_input.size()) # 64x768\n",
        "    features, logits, probs = discriminator(disciminator_input)\n",
        "\n",
        "    # print('disc output', features.size()) #64x768\n",
        "    # print('2: ', logits.size()) #64x152\n",
        "    # print('3: ', probs.size()) #64x152\n",
        "\n",
        "    features_list = torch.split(features, real_batch_size) #split 64x768 into 32,32\n",
        "    D_real_features = features_list[0]\n",
        "    D_fake_features = features_list[1] \n",
        "\n",
        "    logits_list = torch.split(logits, real_batch_size)\n",
        "    D_real_logits = logits_list[0]\n",
        "    D_fake_logits = logits_list[1]  \n",
        "\n",
        "    probs_list = torch.split(probs, real_batch_size)\n",
        "    D_real_probs = probs_list[0]\n",
        "    D_fake_probs = probs_list[1]\n",
        "\n",
        "    #loss\n",
        "\n",
        "    #gen loss\n",
        "    g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + 1e-8))\n",
        "    g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
        "    g_loss = g_loss_d + g_feat_reg\n",
        "\n",
        "    #disc loss\n",
        "    logits = D_real_logits[:,0:-1]\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "    label2one_hot = torch.nn.functional.one_hot(b_labels, 151)\n",
        "    per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
        "    per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
        "    labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
        "\n",
        "    if labeled_example_count == 0:\n",
        "      D_L_Supervised = 0\n",
        "    else:\n",
        "      D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
        "\n",
        "    D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + 1e-8))\n",
        "    D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + 1e-8))\n",
        "    d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
        "\n",
        "    #optimization\n",
        "    gen_optimizer.zero_grad()\n",
        "    dis_optimizer.zero_grad()\n",
        "\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    d_loss.backward()\n",
        "\n",
        "    gen_optimizer.step()\n",
        "    dis_optimizer.step()\n",
        "\n",
        "    tr_g_loss += g_loss.item()\n",
        "    tr_d_loss += d_loss.item()\n",
        "\n",
        "    if apply_scheduler:\n",
        "      scheduler_d.step()\n",
        "      scheduler_g.step()\n",
        "\n",
        "  avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
        "  avg_train_loss_d = tr_d_loss / len(train_dataloader)\n",
        "  \n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss generator: {0:.3f}\".format(avg_train_loss_g))\n",
        "  print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
        "  print(\"  Training epoch took: {:}\".format(training_time))\n",
        "  train_gen_loss_history.append(avg_train_loss_g)\n",
        "  train_disc_loss_history.append(avg_train_loss_d)\n",
        "\n",
        "  #EVALUATION\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  transformer.eval() \n",
        "  discriminator.eval()\n",
        "  generator.eval()\n",
        "\n",
        "  total_val_accuracy = 0\n",
        "   \n",
        "  total_val_loss = 0\n",
        "  nb_test_steps = 0\n",
        "\n",
        "  all_preds = []\n",
        "  all_labels_ids = []\n",
        "\n",
        "  #loss\n",
        "  nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "  for idx, batch in enumerate(val_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():        \n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        _, logits, probs = discriminator(hidden_states)\n",
        "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "        filtered_logits = logits[:,0:-1]\n",
        "        # Accumulate the test loss.\n",
        "        total_val_loss += nll_loss(filtered_logits, b_labels)\n",
        "\n",
        "    # Accumulate the predictions and the input labels\n",
        "    _, preds = torch.max(filtered_logits, 1)\n",
        "    all_preds += preds.detach().cpu()\n",
        "    all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  all_preds = torch.stack(all_preds).numpy()\n",
        "  all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "  val_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "  print(\"  Accuracy: {0:.3f}\".format(val_accuracy))\n",
        "  val_accuracies.append(val_accuracy)\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "  avg_val_loss = avg_val_loss.item()\n",
        "  if avg_val_loss < best_valid_loss:\n",
        "    best_valid_loss = avg_val_loss\n",
        "    torch.save(transformer.state_dict(), 'model_'+model+'.pt')\n",
        "    print(\"Saving...\", epoch)\n",
        "  test_time = format_time(time.time() - t0)\n",
        "    \n",
        "  print(\"  Val Loss: {0:.3f}\".format(avg_val_loss))\n",
        "  print(\"  Val took: {:}\".format(test_time))\n",
        "  val_loss_history.append(avg_val_loss)\n",
        "\n",
        "  training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss generator': avg_train_loss_g,\n",
        "            'Training Loss discriminator': avg_train_loss_d,\n",
        "            'Val Loss': avg_val_loss,\n",
        "            'Val Accur.': val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Val Time': test_time\n",
        "        }\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnXPbu7bkN1P"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyrB8S9_tl-u",
        "outputId": "292ae37b-19a9-45f8-a26d-c43b470518c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.load_state_dict(torch.load('/content/model_10_90.pt'))\n",
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rBWWVtyiPDP",
        "outputId": "40744303-bc32-472e-ed73-466a7d76725d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running test...\n",
            "  Accuracy: 0.889\n",
            "  Test Loss: 0.614\n",
            "  Test took: 0:00:08\n"
          ]
        }
      ],
      "source": [
        "# testing\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running test...\")\n",
        "transformer.load_state_dict(torch.load('model_10_90.pt'))\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "transformer.eval() \n",
        "discriminator.eval()\n",
        "generator.eval()\n",
        "\n",
        "total_test_accuracy = 0\n",
        "  \n",
        "total_test_loss = 0\n",
        "nb_test_steps = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels_ids = []\n",
        "\n",
        "#loss\n",
        "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "for idx, batch in enumerate(test_dataloader):\n",
        "  b_input_ids = batch[0].to(device)\n",
        "  b_input_mask = batch[1].to(device)\n",
        "  b_labels = batch[2].to(device)\n",
        "\n",
        "  with torch.no_grad():        \n",
        "      model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "      hidden_states = model_outputs[-1]\n",
        "      _, logits, probs = discriminator(hidden_states)\n",
        "      filtered_logits = logits[:,0:-1]\n",
        "      # Accumulate the test loss.\n",
        "      total_test_loss += nll_loss(filtered_logits, b_labels)\n",
        "\n",
        "  # Accumulate the predictions and the input labels\n",
        "  _, preds = torch.max(filtered_logits, 1)\n",
        "  all_preds += preds.detach().cpu()\n",
        "  all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "all_preds = torch.stack(all_preds).numpy()\n",
        "all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "avg_test_loss = avg_test_loss.item()\n",
        "\n",
        "test_time = format_time(time.time() - t0)\n",
        "  \n",
        "print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
        "print(\"  Test took: {:}\".format(test_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDVRIMlMFjuh"
      },
      "source": [
        "The first split gets a pretty high accuracy of 88.9%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw8-JkYbNuTd"
      },
      "source": [
        "### Loss & Accuracy curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LYmvWfgDJGDO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "R8APdI2FI_sm",
        "outputId": "6db1f939-e7a6-48cc-ac3d-0ecfa500a138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb9a20b1af0>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(10),train_gen_loss_history,'-',linewidth=3,label='Generator Loss')\n",
        "plt.plot(range(10),train_disc_loss_history,'-',linewidth=3,label='Discriminator Loss')\n",
        "plt.plot(range(10),val_loss_history,'-',linewidth=3,label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title(\"Split 10_90\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "rZnmK6qTJtoU",
        "outputId": "79610ad7-93da-4f29-c77c-18edfe53b84d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb9a1ffd730>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(10), val_accuracies,'-', linewidth=3, label='Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.title(\"Split 10_90\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptD8J0yrNp2W"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjkB0uezNxf4",
        "outputId": "97f2be33-1aa6-4335-f4f9-2d6efeabf337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "stats = []\n",
        "stats.append(\n",
        "    {\n",
        "    'gen train loss history': train_gen_loss_history ,\n",
        "    'disc train loss history': train_disc_loss_history,\n",
        "    'val loss': val_loss_history,\n",
        "    'val accuracy': val_accuracies,\n",
        "    'test loss': avg_test_loss,\n",
        "    'test accuracy': test_accuracy\n",
        "    }\n",
        ")\n",
        "\n",
        "with open('stats_'+model+'best'+'.txt','w') as f_out:\n",
        "  f_out.write(str(stats[0]))\n",
        "  print('Done')\n",
        "  f_out.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH5SmKoldaRD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e9b70e291f9440293329b3799caff9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18da525d58064fcfb22a6236bd5088b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a170be3e8c4219b758daa77d2eece9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f1a996732d48569e14b762201409f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267b8d6cd50f4f7892aa2c5e15d7bdf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c90c1f75c040ee91f9eac4a7641d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "499fd0748e2349f592d43357b8ea3d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02c2fe0893b4f26b83969a581184179",
            "placeholder": "​",
            "style": "IPY_MODEL_c529f5432daf4a7291de8c0ab5b299cc",
            "value": "Downloading: 100%"
          }
        },
        "4a859afe248a468fbdc45a40b0125b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9d3961e0bc42949b7f63e1d9decf0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5506243f1afb4aa2b4aecfd5cf078d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c58e3c470941dd9825c7cb738f982f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6514207f29be45b1ac913d0925511d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75019ed62dd9446ebae6700dc9f92a9c",
            "placeholder": "​",
            "style": "IPY_MODEL_8f721a42d6d640a38c97901b40211b3a",
            "value": " 570/570 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "67d2461721e64d218ca0bf34ab47e9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d0f8fd67ed47ffa7382bda25cfb96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9d3961e0bc42949b7f63e1d9decf0d",
            "placeholder": "​",
            "style": "IPY_MODEL_856cbeaec00f49ae84f24a00390587ac",
            "value": "Downloading: 100%"
          }
        },
        "69e33f014cb9451e81afc7261cc38fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bc12fe0c9e4adf84a4275a9eb10715",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3ee711ea62545ccbad4a99b33e738ea",
            "value": 570
          }
        },
        "7237144b1d9d4a039759fb245b9f7ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_267b8d6cd50f4f7892aa2c5e15d7bdf2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cb1124b29e340e6a464e9ded3750b43",
            "value": 231508
          }
        },
        "75019ed62dd9446ebae6700dc9f92a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb1124b29e340e6a464e9ded3750b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ef90efc0e624776b46d9b4f59661e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69d0f8fd67ed47ffa7382bda25cfb96c",
              "IPY_MODEL_69e33f014cb9451e81afc7261cc38fa9",
              "IPY_MODEL_6514207f29be45b1ac913d0925511d92"
            ],
            "layout": "IPY_MODEL_f48266fae8734a09bd9bc673e89299d7"
          }
        },
        "80cd277fe3d84768b29f46b90111883d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_499fd0748e2349f592d43357b8ea3d69",
              "IPY_MODEL_7237144b1d9d4a039759fb245b9f7ead",
              "IPY_MODEL_eeb80e2d8f3b40ed88bc6fb8c566c006"
            ],
            "layout": "IPY_MODEL_0e9b70e291f9440293329b3799caff9b"
          }
        },
        "856cbeaec00f49ae84f24a00390587ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85bc12fe0c9e4adf84a4275a9eb10715": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f721a42d6d640a38c97901b40211b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f7c14cb1c644158d7d0fdbf2d4a34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18da525d58064fcfb22a6236bd5088b7",
            "placeholder": "​",
            "style": "IPY_MODEL_46c90c1f75c040ee91f9eac4a7641d7d",
            "value": "Downloading: 100%"
          }
        },
        "9c537e79551044d08879682ceb1ddb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99f7c14cb1c644158d7d0fdbf2d4a34c",
              "IPY_MODEL_ef7c05fcde6f4862b77f41cac6c13bc0",
              "IPY_MODEL_c39e68ce32354d55a8674b33863467b9"
            ],
            "layout": "IPY_MODEL_5506243f1afb4aa2b4aecfd5cf078d6e"
          }
        },
        "b02c2fe0893b4f26b83969a581184179": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39e68ce32354d55a8674b33863467b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f1a996732d48569e14b762201409f0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a859afe248a468fbdc45a40b0125b91",
            "value": " 440M/440M [00:06&lt;00:00, 68.6MB/s]"
          }
        },
        "c529f5432daf4a7291de8c0ab5b299cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3ee711ea62545ccbad4a99b33e738ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4f356fd1db94250a2df23933948d5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eeb80e2d8f3b40ed88bc6fb8c566c006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c58e3c470941dd9825c7cb738f982f",
            "placeholder": "​",
            "style": "IPY_MODEL_20a170be3e8c4219b758daa77d2eece9",
            "value": " 232k/232k [00:00&lt;00:00, 942kB/s]"
          }
        },
        "ef7c05fcde6f4862b77f41cac6c13bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d2461721e64d218ca0bf34ab47e9e5",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4f356fd1db94250a2df23933948d5a7",
            "value": 440473133
          }
        },
        "f48266fae8734a09bd9bc673e89299d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
